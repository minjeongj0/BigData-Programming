{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "institutional-release",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228818944/228813984 [==============================] - 11s 0us/step\n",
      "3670\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "################################ 이미지 다운로드 ########################################\n",
    "# 분석하기 전에 파일 시스템 경로(../.../.../...)를 입출력하기 위해 사용\n",
    "import pathlib\n",
    "\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
    "                                   fname='flower_photos', \n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# 이미지 개수 출력\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial-roads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whals\\.keras\\datasets\\flower_photos\n"
     ]
    }
   ],
   "source": [
    "# 장미꽃 출력\n",
    "roses = list(data_dir.glob('roses/*'))\n",
    "\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "collectible-wireless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 625)               2880625   \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 5)                 3130      \n",
      "=================================================================\n",
      "Total params: 2,977,003\n",
      "Trainable params: 2,977,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "92/92 [==============================] - 32s 282ms/step - loss: 1.5037 - accuracy: 0.3090\n",
      "Epoch 2/30\n",
      "92/92 [==============================] - 34s 307ms/step - loss: 1.1951 - accuracy: 0.4796\n",
      "Epoch 3/30\n",
      "92/92 [==============================] - 33s 301ms/step - loss: 1.1206 - accuracy: 0.5510\n",
      "Epoch 4/30\n",
      "92/92 [==============================] - 35s 319ms/step - loss: 1.0191 - accuracy: 0.5942\n",
      "Epoch 5/30\n",
      "92/92 [==============================] - 36s 336ms/step - loss: 0.9449 - accuracy: 0.6135\n",
      "Epoch 6/30\n",
      "92/92 [==============================] - 36s 333ms/step - loss: 0.9019 - accuracy: 0.6459\n",
      "Epoch 7/30\n",
      "92/92 [==============================] - 36s 331ms/step - loss: 0.8867 - accuracy: 0.6407\n",
      "Epoch 8/30\n",
      "92/92 [==============================] - 36s 333ms/step - loss: 0.8352 - accuracy: 0.6653\n",
      "Epoch 9/30\n",
      "92/92 [==============================] - 36s 331ms/step - loss: 0.7798 - accuracy: 0.7017\n",
      "Epoch 10/30\n",
      "92/92 [==============================] - 36s 334ms/step - loss: 0.7207 - accuracy: 0.7136\n",
      "Epoch 11/30\n",
      "92/92 [==============================] - 36s 332ms/step - loss: 0.7149 - accuracy: 0.7304\n",
      "Epoch 12/30\n",
      "92/92 [==============================] - 36s 333ms/step - loss: 0.6700 - accuracy: 0.7410\n",
      "Epoch 13/30\n",
      "92/92 [==============================] - 36s 329ms/step - loss: 0.6245 - accuracy: 0.7673\n",
      "Epoch 14/30\n",
      "92/92 [==============================] - 36s 332ms/step - loss: 0.5858 - accuracy: 0.7851\n",
      "Epoch 15/30\n",
      "92/92 [==============================] - 36s 330ms/step - loss: 0.5578 - accuracy: 0.7863\n",
      "Epoch 16/30\n",
      "92/92 [==============================] - 36s 328ms/step - loss: 0.5683 - accuracy: 0.7809\n",
      "Epoch 17/30\n",
      "92/92 [==============================] - 36s 333ms/step - loss: 0.5086 - accuracy: 0.8068\n",
      "Epoch 18/30\n",
      "92/92 [==============================] - 36s 332ms/step - loss: 0.4627 - accuracy: 0.8228\n",
      "Epoch 19/30\n",
      "92/92 [==============================] - 35s 328ms/step - loss: 0.4582 - accuracy: 0.8358\n",
      "Epoch 20/30\n",
      "92/92 [==============================] - 36s 329ms/step - loss: 0.4258 - accuracy: 0.8434\n",
      "Epoch 21/30\n",
      "92/92 [==============================] - 36s 332ms/step - loss: 0.4014 - accuracy: 0.8547\n",
      "Epoch 22/30\n",
      "92/92 [==============================] - 36s 340ms/step - loss: 0.3442 - accuracy: 0.8746\n",
      "Epoch 23/30\n",
      "92/92 [==============================] - 36s 331ms/step - loss: 0.2888 - accuracy: 0.8969\n",
      "Epoch 24/30\n",
      "92/92 [==============================] - 36s 330ms/step - loss: 0.3054 - accuracy: 0.8811\n",
      "Epoch 25/30\n",
      "92/92 [==============================] - 36s 334ms/step - loss: 0.2731 - accuracy: 0.9031\n",
      "Epoch 26/30\n",
      "92/92 [==============================] - 36s 333ms/step - loss: 0.2580 - accuracy: 0.9146\n",
      "Epoch 27/30\n",
      "92/92 [==============================] - 36s 332ms/step - loss: 0.2314 - accuracy: 0.9101\n",
      "Epoch 28/30\n",
      "92/92 [==============================] - 36s 335ms/step - loss: 0.2191 - accuracy: 0.9307\n",
      "Epoch 29/30\n",
      "92/92 [==============================] - 36s 329ms/step - loss: 0.1894 - accuracy: 0.9384\n",
      "Epoch 30/30\n",
      "92/92 [==============================] - 35s 324ms/step - loss: 0.1946 - accuracy: 0.9360\n",
      "31/31 [==============================] - 8s 76ms/step - loss: 0.1070 - accuracy: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10704797506332397, 0.9738562107086182]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################### 전처리기 ##############################################\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "caltech_dir = \"C:/Users/whals/.keras/datasets/flower_photos\"\n",
    "categories = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
    "nb_classes = len(categories)  # 5\n",
    "\n",
    "#lists = list(data_dir.glob('*/*.jpg'))\n",
    "\n",
    "\n",
    "# 이미지 크기 지정 (64 X 64)\n",
    "#pixels = image_w * image_h * 3\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "batch_size = 30\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)]  # one-hot준비 [0,0,0,0,0]\n",
    "    label[idx] = 1   # one-hot 리스트 생성\n",
    "    # 이미지\n",
    "    image_dir = caltech_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.iamge형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 3:1학습과 테스트 데이터 분리\n",
    "train_size = int(0.75 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "# 나머지를 테스트 용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "########################### 모델 생성 ###################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# softmax\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "#optimizer = \"Adam\"        \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, batch_size=batch_size, epochs = 35)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "square-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_51 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 625)               2880625   \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 5)                 3130      \n",
      "=================================================================\n",
      "Total params: 2,977,003\n",
      "Trainable params: 2,977,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "92/92 [==============================] - 35s 318ms/step - loss: 1.6780 - accuracy: 0.3186\n",
      "Epoch 2/30\n",
      "92/92 [==============================] - 35s 326ms/step - loss: 1.2440 - accuracy: 0.4763\n",
      "Epoch 3/30\n",
      "92/92 [==============================] - 37s 342ms/step - loss: 1.1097 - accuracy: 0.5502\n",
      "Epoch 4/30\n",
      "92/92 [==============================] - 38s 354ms/step - loss: 0.9766 - accuracy: 0.6314\n",
      "Epoch 5/30\n",
      "92/92 [==============================] - 36s 338ms/step - loss: 0.8838 - accuracy: 0.6434\n",
      "Epoch 6/30\n",
      "92/92 [==============================] - 37s 338ms/step - loss: 0.8681 - accuracy: 0.6673\n",
      "Epoch 7/30\n",
      "92/92 [==============================] - 36s 337ms/step - loss: 0.7881 - accuracy: 0.6926\n",
      "Epoch 8/30\n",
      "92/92 [==============================] - 37s 340ms/step - loss: 0.7682 - accuracy: 0.7092\n",
      "Epoch 9/30\n",
      "92/92 [==============================] - 37s 343ms/step - loss: 0.6946 - accuracy: 0.7386\n",
      "Epoch 10/30\n",
      "92/92 [==============================] - 37s 342ms/step - loss: 0.6400 - accuracy: 0.7584\n",
      "Epoch 11/30\n",
      "92/92 [==============================] - 37s 344ms/step - loss: 0.6548 - accuracy: 0.7493\n",
      "Epoch 12/30\n",
      "92/92 [==============================] - 37s 348ms/step - loss: 0.6121 - accuracy: 0.7704\n",
      "Epoch 13/30\n",
      "92/92 [==============================] - 38s 350ms/step - loss: 0.5814 - accuracy: 0.7831\n",
      "Epoch 14/30\n",
      "92/92 [==============================] - 37s 345ms/step - loss: 0.5391 - accuracy: 0.7924\n",
      "Epoch 15/30\n",
      "92/92 [==============================] - 37s 337ms/step - loss: 0.5356 - accuracy: 0.8027\n",
      "Epoch 16/30\n",
      "92/92 [==============================] - 37s 341ms/step - loss: 0.5159 - accuracy: 0.8079\n",
      "Epoch 17/30\n",
      "92/92 [==============================] - 37s 347ms/step - loss: 0.4899 - accuracy: 0.8186\n",
      "Epoch 18/30\n",
      "92/92 [==============================] - 37s 343ms/step - loss: 0.4325 - accuracy: 0.8429\n",
      "Epoch 19/30\n",
      "92/92 [==============================] - 37s 342ms/step - loss: 0.4101 - accuracy: 0.8377\n",
      "Epoch 20/30\n",
      "92/92 [==============================] - 37s 339ms/step - loss: 0.3850 - accuracy: 0.8701\n",
      "Epoch 21/30\n",
      "92/92 [==============================] - 37s 345ms/step - loss: 0.3867 - accuracy: 0.8468\n",
      "Epoch 22/30\n",
      "92/92 [==============================] - 37s 342ms/step - loss: 0.3788 - accuracy: 0.8647\n",
      "Epoch 23/30\n",
      "92/92 [==============================] - 36s 336ms/step - loss: 0.3418 - accuracy: 0.8730\n",
      "Epoch 24/30\n",
      "92/92 [==============================] - 37s 340ms/step - loss: 0.3335 - accuracy: 0.8692\n",
      "Epoch 25/30\n",
      "92/92 [==============================] - 37s 342ms/step - loss: 0.3318 - accuracy: 0.8788\n",
      "Epoch 26/30\n",
      "92/92 [==============================] - 37s 342ms/step - loss: 0.2954 - accuracy: 0.8965\n",
      "Epoch 27/30\n",
      "92/92 [==============================] - 37s 349ms/step - loss: 0.2768 - accuracy: 0.8973\n",
      "Epoch 28/30\n",
      "92/92 [==============================] - 37s 339ms/step - loss: 0.3043 - accuracy: 0.8922\n",
      "Epoch 29/30\n",
      "92/92 [==============================] - 37s 340ms/step - loss: 0.2617 - accuracy: 0.9067\n",
      "Epoch 30/30\n",
      "92/92 [==============================] - 37s 343ms/step - loss: 0.2680 - accuracy: 0.8969\n",
      "31/31 [==============================] - 8s 67ms/step - loss: 0.1081 - accuracy: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10813818126916885, 0.9694989323616028]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##################################### 전처리기\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "caltech_dir = \"C:/Users/whals/.keras/datasets/flower_photos\"\n",
    "categories = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
    "nb_classes = len(categories)  # 5\n",
    "\n",
    "lists = list(data_dir.glob('*/*.jpg'))\n",
    "\n",
    "\n",
    "# 이미지 크기 지정 (64 X 64)\n",
    "#pixels = image_w * image_h * 3\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "batch_size = 30\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)]  # one-hot준비 [0,0,0,0,0]\n",
    "    label[idx] = 1   # one-hot 리스트 생성\n",
    "    # 이미지\n",
    "    image_dir = caltech_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.iamge형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 3:1학습과 테스트 데이터 분리\n",
    "train_size = int(0.75 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(30)\n",
    "\n",
    "# 나머지를 테스트 용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(30)\n",
    "\n",
    "########################### 모델 생성 ###################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# softmax\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "#Adam          \n",
    "model.compile(optimizer = \"RMSProp\",  # optimizer=tf.keras.optimizers.Adam(0.001)\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, batch_size=batch_size, epochs = 30)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-karma",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
